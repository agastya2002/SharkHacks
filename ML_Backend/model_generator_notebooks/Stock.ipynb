{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              Open   High    Low  Close    Volume  Name\n",
       "Date                                                  \n",
       "2006-01-03  77.76  79.35  77.24  79.11   3117200   MMM\n",
       "2006-01-04  79.49  79.49  78.25  78.71   2558000   MMM\n",
       "2006-01-05  78.41  78.65  77.56  77.99   2529500   MMM\n",
       "2006-01-06  78.64  78.90  77.64  78.63   2479500   MMM\n",
       "2006-01-09  78.50  79.83  78.46  79.02   1845600   MMM\n",
       "...           ...    ...    ...    ...       ...   ...\n",
       "2017-12-22  71.42  71.87  71.22  71.58  10979165  AABA\n",
       "2017-12-26  70.94  71.39  69.63  69.86   8542802  AABA\n",
       "2017-12-27  69.77  70.49  69.69  70.06   6345124  AABA\n",
       "2017-12-28  70.12  70.32  69.51  69.82   7556877  AABA\n",
       "2017-12-29  69.79  70.13  69.43  69.85   6613070  AABA\n",
       "\n",
       "[93587 rows x 6 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('STONK.csv',index_col='Date',parse_dates=['Date'])\n",
    "# df = df[(df['Name']=='AAPL')]\n",
    "df = df.dropna()\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with only the 'Close column\n",
    "data = df.filter(['High'])\n",
    "#Convert the dataframe to a numpy array\n",
    "dataset = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05983884],\n",
       "       [0.0599549 ],\n",
       "       [0.05925852],\n",
       "       ...,\n",
       "       [0.0524937 ],\n",
       "       [0.05235277],\n",
       "       [0.05219525]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.05983884, 0.0599549 , 0.05925852, 0.05946578, 0.06023677,\n",
      "       0.05955697, 0.05926681, 0.05891033, 0.05888546, 0.05840463,\n",
      "       0.05812276, 0.05819737, 0.05781602, 0.05725229, 0.05673   ,\n",
      "       0.05526263, 0.05493103, 0.0547818 , 0.05485641, 0.0547818 ,\n",
      "       0.05490615, 0.05513828, 0.05382014, 0.05316521, 0.05315692,\n",
      "       0.05314863, 0.05447506, 0.05456626, 0.05492274, 0.05550305,\n",
      "       0.05555279, 0.0548647 , 0.05552792, 0.05548647, 0.05518802,\n",
      "       0.05546989, 0.05553621, 0.05595072, 0.05546989, 0.05556108,\n",
      "       0.05523776, 0.05481496, 0.05440874, 0.05402739, 0.05463258,\n",
      "       0.05437558, 0.05440874, 0.05417661, 0.05519631, 0.05560253,\n",
      "       0.05661394, 0.05660565, 0.0563901 , 0.05651446, 0.05718597,\n",
      "       0.05785747, 0.05794038, 0.05808131, 0.05805644, 0.05933313])]\n",
      "[0.05840462926117522]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create the training data set\n",
    "#Create the scaled training data set\n",
    "train_data = scaled_data\n",
    "#Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data), 60):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "        \n",
    "# Convert the x_train and y_train to numpy arrays \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "#Reshape the data\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the x_train and y_train to numpy arrays \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "#Reshape the data\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_train.shape\n",
    "assert not np.any(np.isnan(x_train))\n",
    "assert not np.any(np.isnan(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1559/1559 [==============================] - 27s 17ms/step - loss: 6.5471e-04\n",
      "Epoch 2/10\n",
      "1559/1559 [==============================] - 26s 17ms/step - loss: 1.3945e-04\n",
      "Epoch 3/10\n",
      "1559/1559 [==============================] - 27s 17ms/step - loss: 3.7667e-04 0s - loss: 3.7744e- - ETA: 0s - loss: 3.7711e-0\n",
      "Epoch 4/10\n",
      "1559/1559 [==============================] - 29s 19ms/step - loss: 2.3303e-04\n",
      "Epoch 5/10\n",
      "1559/1559 [==============================] - 29s 18ms/step - loss: 2.5577e-04\n",
      "Epoch 6/10\n",
      "1559/1559 [==============================] - 28s 18ms/step - loss: 9.6650e-05\n",
      "Epoch 7/10\n",
      "1559/1559 [==============================] - 28s 18ms/step - loss: 1.5565e-04\n",
      "Epoch 8/10\n",
      "1559/1559 [==============================] - 28s 18ms/step - loss: 2.2281e-04\n",
      "Epoch 9/10\n",
      "1559/1559 [==============================] - 30s 19ms/step - loss: 1.6600e-05 4s - los - ETA: 2 - ETA: 1s\n",
      "Epoch 10/10\n",
      "1559/1559 [==============================] - 28s 18ms/step - loss: 2.1599e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2515b53bac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "#Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences= False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('StonkPredict.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2020-09-10    165.240563\n",
       "2020-09-11    165.270296\n",
       "2020-09-14    167.976880\n",
       "2020-09-15    168.472602\n",
       "2020-09-16    169.632573\n",
       "                 ...    \n",
       "2020-11-30    176.000000\n",
       "2020-12-01    175.690002\n",
       "2020-12-02    172.580002\n",
       "2020-12-03    173.389999\n",
       "2020-12-04    173.160004\n",
       "Name: High, Length: 61, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf = yf.Ticker(\"MMM\").history(period=\"61d\").High\n",
    "ydf = ydf.dropna()\n",
    "ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ydf.values[:60]\n",
    "dataset = dataset.reshape(-1, 1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.reshape(scaled_data, (1, scaled_data.shape[0], 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.02971\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_pred)\n",
    "pred = scaler.inverse_transform(pred)\n",
    "print(pred[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
